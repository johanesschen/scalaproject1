## Design Considerations

- Spark RDD used throughout for core logic, adhering strictly to the requirement.
- Join operation avoided using Spark's broadcast variables.
- Configurable via HOCON `.conf` file and overridable by environment variables.
- Modular functions (deduplication, ranking, config reading) enable clean testing and reuse.
- Ranking logic decoupled via injected function parameter.
- Logging via log4j for operational transparency.
- The code is compliant with scalastyle, including proper header, and avoids println statements.

## Spark Configurations Proposed

- local[*] used during development; to be replaced with cluster manager configs.
- Broadcast join used for efficient small reference table (location mapping).
- ReduceByKey used for minimal shuffle during aggregation.
